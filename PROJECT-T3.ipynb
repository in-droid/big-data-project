{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becf0e2-0093-4e36-a817-5f832180f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 659,543 rows × 37 columns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d7879a13f243fbae18d6bb9d2256b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>rows</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>read_s</th>\n",
       "      <th>size_human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csv</td>\n",
       "      <td>659543</td>\n",
       "      <td>83697918</td>\n",
       "      <td>1.639582</td>\n",
       "      <td>79.8 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>csv.gz</td>\n",
       "      <td>659543</td>\n",
       "      <td>13108234</td>\n",
       "      <td>1.927728</td>\n",
       "      <td>12.5 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duckdb</td>\n",
       "      <td>659543</td>\n",
       "      <td>18886656</td>\n",
       "      <td>2.100156</td>\n",
       "      <td>18.0 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hdf5(table)</td>\n",
       "      <td>659543</td>\n",
       "      <td>28618353</td>\n",
       "      <td>7.024108</td>\n",
       "      <td>27.3 MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        format    rows  size_bytes    read_s size_human\n",
       "0          csv  659543    83697918  1.639582    79.8 MB\n",
       "1       csv.gz  659543    13108234  1.927728    12.5 MB\n",
       "2       duckdb  659543    18886656  2.100156    18.0 MB\n",
       "3  hdf5(table)  659543    28618353  7.024108    27.3 MB"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import duckdb\n",
    "\n",
    "\n",
    "INPUT_ROOT = Path(\"/d/hpc/projects/FRI/bigdata/students/in7357/cleaned_parquet/GREEN\")\n",
    "YEAR = 2024\n",
    "OUTDIR = Path(f\"/d/hpc/projects/FRI/bigdata/students/in7357/exports/green_{YEAR}\")\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n",
    "        if n < 1024 or unit == \"TB\":\n",
    "            return f\"{n:.1f} {unit}\" if unit != \"B\" else f\"{n} {unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.1f} TB\"\n",
    "\n",
    "def read_year_partition(input_root: Path, year: int) -> pd.DataFrame:\n",
    "    part_dir = input_root / f\"year={year}\"\n",
    "    dataset = ds.dataset(str(part_dir), format=\"parquet\")\n",
    "    return dataset.to_table().to_pandas()\n",
    "\n",
    "def export_all(df: pd.DataFrame, outdir: Path, year: int):\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    outputs = {}\n",
    "\n",
    "    # CSV\n",
    "    csv_path = outdir / f\"green_{year}.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    outputs[\"csv\"] = csv_path\n",
    "\n",
    "    # CSV.GZ\n",
    "    csv_gz_path = outdir / f\"green_{year}.csv.gz\"\n",
    "    df.to_csv(csv_gz_path, index=False, compression=\"gzip\")\n",
    "    outputs[\"csv.gz\"] = csv_gz_path\n",
    "\n",
    "    # HDF5\n",
    "    h5_path = outdir / f\"green_{year}.h5\"\n",
    "    \n",
    "    df_hdf = df.copy()\n",
    "    for col in df_hdf.select_dtypes(include=\"string\"):\n",
    "        df_hdf[col] = df_hdf[col].astype(\"object\")\n",
    "\n",
    "    df_hdf.to_hdf(\n",
    "        h5_path,\n",
    "        key=\"green\",\n",
    "        format=\"table\",\n",
    "        mode=\"w\",\n",
    "        complib=\"blosc\",\n",
    "        complevel=9,\n",
    "    )\n",
    "    outputs[\"hdf5\"] = h5_path\n",
    "\n",
    "    # DuckDB\n",
    "    duckdb_path = outdir / f\"green_{year}.duckdb\"\n",
    "    if duckdb_path.exists():\n",
    "        duckdb_path.unlink()\n",
    "    con = duckdb.connect(str(duckdb_path))\n",
    "    con.register(\"df\", df)\n",
    "    con.execute(f\"CREATE TABLE green_{year} AS SELECT * FROM df\")\n",
    "    con.unregister(\"df\")\n",
    "    con.close()\n",
    "    outputs[\"duckdb\"] = duckdb_path\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def file_size(path: Path) -> int:\n",
    "    return path.stat().st_size\n",
    "\n",
    "def timed_read(func, *args, **kwargs):\n",
    "    best = float(\"inf\")\n",
    "    for _ in range(2):\n",
    "        t0 = time.perf_counter()\n",
    "        df = func(*args, **kwargs)\n",
    "        dt = time.perf_counter() - t0\n",
    "        best = min(best, dt)\n",
    "    df = func(*args, **kwargs) \n",
    "    return df, best\n",
    "\n",
    "def measure_reads(paths):\n",
    "    results = []\n",
    "\n",
    "    # CSV\n",
    "    df_csv, t_csv = timed_read(pd.read_csv, paths[\"csv\"])\n",
    "    results.append({\"format\": \"csv\", \"rows\": len(df_csv),\n",
    "                    \"size_bytes\": file_size(paths[\"csv\"]),\n",
    "                    \"read_s\": t_csv})\n",
    "\n",
    "    # CSV.GZ\n",
    "    df_gz, t_gz = timed_read(pd.read_csv, paths[\"csv.gz\"])\n",
    "    results.append({\"format\": \"csv.gz\", \"rows\": len(df_gz),\n",
    "                    \"size_bytes\": file_size(paths[\"csv.gz\"]),\n",
    "                    \"read_s\": t_gz})\n",
    "\n",
    "    # HDF5\n",
    "    df_h5, t_h5 = timed_read(pd.read_hdf, paths[\"hdf5\"], key=\"green\")\n",
    "    results.append({\"format\": \"hdf5(table)\", \"rows\": len(df_h5),\n",
    "                    \"size_bytes\": file_size(paths[\"hdf5\"]),\n",
    "                    \"read_s\": t_h5})\n",
    "\n",
    "    # DuckDB\n",
    "    def read_duckdb(path):\n",
    "        con = duckdb.connect(str(path), read_only=True)\n",
    "        year = int(path.stem.split(\"_\")[-1])\n",
    "        df = con.execute(f\"SELECT * FROM green_{year}\").df()\n",
    "        con.close()\n",
    "        return df\n",
    "\n",
    "    df_ddb, t_ddb = timed_read(read_duckdb, paths[\"duckdb\"])\n",
    "    results.append({\"format\": \"duckdb\", \"rows\": len(df_ddb),\n",
    "                    \"size_bytes\": file_size(paths[\"duckdb\"]),\n",
    "                    \"read_s\": t_ddb})\n",
    "\n",
    "    out = pd.DataFrame(results)\n",
    "    out[\"size_human\"] = out[\"size_bytes\"].map(human_bytes)\n",
    "    return out.sort_values(\"read_s\").reset_index(drop=True)\n",
    "\n",
    "# --- Run ---\n",
    "df = read_year_partition(INPUT_ROOT, YEAR)\n",
    "print(f\"Loaded: {len(df):,} rows × {len(df.columns)} columns\")\n",
    "\n",
    "paths = export_all(df, OUTDIR, YEAR)\n",
    "summary = measure_reads(paths)\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22948741-c743-4868-a450-b0a0dea45a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('/d/hpc/projects/FRI/bigdata/students/in7357/read_size_TASK3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10a759-5f96-4629-8b44-afaf47e0c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (big_data311)",
   "language": "python",
   "name": "big_data311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
